{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODxYF/jjFwJtHgkPzlc2P7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimajr/MachineLearning2023/blob/main/HW/HW3/Q5/hw3_Q5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch anfis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKhZoxqK67AG",
        "outputId": "69919e55-2bfa-4b0a-dccd-e8c38f9c08cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Collecting anfis\n",
            "  Downloading anfis-0.3.1-py3-none-any.whl.metadata (756 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from anfis) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from anfis) (3.10.0)\n",
            "Collecting scikit-fuzzy (from anfis)\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (4.55.6)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->anfis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->anfis) (1.17.0)\n",
            "Downloading anfis-0.3.1-py3-none-any.whl (7.4 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy, anfis\n",
            "Successfully installed anfis-0.3.1 scikit-fuzzy-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HW3-Q5\n"
      ],
      "metadata": {
        "id": "ErCcfzCn6MGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- بارگذاری داده‌ها ---\n",
        "df = pd.read_csv(\"/content/AirQualityUCI.csv\", sep=';', encoding='utf-8', low_memory=False)\n",
        "\n",
        "# نمایش خلاصه‌ای از داده‌ها برای بررسی مقدارهای NaN\n",
        "print(\"قبل از پردازش:\")\n",
        "print(df.info())\n",
        "\n",
        "# انتخاب فقط ستون‌های عددی و حذف مقدارهای خالی\n",
        "df_numeric = df.select_dtypes(include=[np.number]).dropna()\n",
        "\n",
        "# جداسازی ویژگی‌ها و خروجی\n",
        "X = df_numeric.iloc[:, :-1].values\n",
        "y = df_numeric.iloc[:, -1].values.reshape(-1, 1)\n",
        "\n",
        "# بررسی مقدار NaN و Inf\n",
        "print(\"تعداد مقدار NaN در X:\", np.isnan(X).sum())\n",
        "print(\"تعداد مقدار Inf در X:\", np.isinf(X).sum())\n",
        "print(\"تعداد مقدار NaN در y:\", np.isnan(y).sum())\n",
        "\n",
        "# جایگذاری مقدارهای NaN و Inf با میانگین هر ستون\n",
        "X = np.nan_to_num(X, nan=np.nanmean(X))\n",
        "y = np.nan_to_num(y, nan=np.nanmean(y))\n",
        "\n",
        "# بررسی ابعاد X و y قبل از نرمال‌سازی\n",
        "print(\"ابعاد X قبل از نرمال‌سازی:\", X.shape)\n",
        "print(\"ابعاد y قبل از نرمال‌سازی:\", y.shape)\n",
        "\n",
        "# نرمال‌سازی داده‌ها\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y).flatten()\n",
        "\n",
        "# بررسی ابعاد X و y بعد از نرمال‌سازی\n",
        "print(\"ابعاد X بعد از نرمال‌سازی:\", X_scaled.shape)\n",
        "print(\"ابعاد y بعد از نرمال‌سازی:\", y_scaled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "WwRsypMG6PTM",
        "outputId": "e9e452be-da7a-4a3f-c06f-4ad287d82933"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "قبل از پردازش:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9471 entries, 0 to 9470\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Date           9357 non-null   object \n",
            " 1   Time           9357 non-null   object \n",
            " 2   CO(GT)         9357 non-null   object \n",
            " 3   PT08.S1(CO)    9357 non-null   float64\n",
            " 4   NMHC(GT)       9357 non-null   float64\n",
            " 5   C6H6(GT)       9357 non-null   object \n",
            " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
            " 7   NOx(GT)        9357 non-null   float64\n",
            " 8   PT08.S3(NOx)   9357 non-null   float64\n",
            " 9   NO2(GT)        9357 non-null   float64\n",
            " 10  PT08.S4(NO2)   9357 non-null   float64\n",
            " 11  PT08.S5(O3)    9357 non-null   float64\n",
            " 12  T              9357 non-null   object \n",
            " 13  RH             9357 non-null   object \n",
            " 14  AH             9357 non-null   object \n",
            " 15  Unnamed: 15    0 non-null      float64\n",
            " 16  Unnamed: 16    0 non-null      float64\n",
            "dtypes: float64(10), object(7)\n",
            "memory usage: 1.2+ MB\n",
            "None\n",
            "تعداد مقدار NaN در X: 0\n",
            "تعداد مقدار Inf در X: 0\n",
            "تعداد مقدار NaN در y: 0\n",
            "ابعاد X قبل از نرمال‌سازی: (0, 9)\n",
            "ابعاد y قبل از نرمال‌سازی: (0, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-21649a9158e9>:25: RuntimeWarning: Mean of empty slice\n",
            "  X = np.nan_to_num(X, nan=np.nanmean(X))\n",
            "<ipython-input-1-21649a9158e9>:26: RuntimeWarning: Mean of empty slice\n",
            "  y = np.nan_to_num(y, nan=np.nanmean(y))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21649a9158e9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mscaler_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mscaler_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0my_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# نمایش اطلاعات اولیه برای بررسی NaN و ستون‌های مشکل‌دار\n",
        "print(\"اطلاعات اولیه داده‌ها:\")\n",
        "print(df.info())\n",
        "\n",
        "# انتخاب فقط ستون‌های عددی و بررسی مقدارهای NaN\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "print(\"\\nتعداد مقدارهای NaN در هر ستون:\")\n",
        "print(df_numeric.isna().sum())\n",
        "\n",
        "# حذف ستون‌هایی که مقدار عددی ندارند (تماماً NaN هستند)\n",
        "df_numeric = df_numeric.dropna(axis=1, how='all')\n",
        "\n",
        "# حذف سطرهایی که مقدارهای NaN دارند\n",
        "df_cleaned = df_numeric.dropna()\n",
        "\n",
        "# بررسی ابعاد جدید\n",
        "print(\"\\nابعاد داده‌ها بعد از حذف مقدارهای NaN:\", df_cleaned.shape)\n",
        "\n",
        "# جداسازی ویژگی‌ها و خروجی\n",
        "X = df_cleaned.iloc[:, :-1].values\n",
        "y = df_cleaned.iloc[:, -1].values.reshape(-1, 1)\n",
        "\n",
        "# بررسی مقدار NaN و Inf در X\n",
        "print(\"\\nتعداد مقدار NaN در X:\", np.isnan(X).sum())\n",
        "print(\"تعداد مقدار Inf در X:\", np.isinf(X).sum())\n",
        "\n",
        "# جایگذاری مقدارهای NaN و Inf با مقدار میانگین هر ستون\n",
        "X = np.nan_to_num(X, nan=np.nanmean(X))\n",
        "y = np.nan_to_num(y, nan=np.nanmean(y))\n",
        "\n",
        "# بررسی دوباره ابعاد\n",
        "print(\"ابعاد X بعد از پردازش:\", X.shape)\n",
        "print(\"ابعاد y بعد از پردازش:\", y.shape)\n",
        "\n",
        "# اجرای نرمال‌سازی داده‌ها\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y).flatten()\n",
        "\n",
        "print(\"\\n✅ داده‌ها با موفقیت نرمال‌سازی شدند!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCFd4diC-7PK",
        "outputId": "c4428763-546c-42ec-bcc7-4a36b0e4b38e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "اطلاعات اولیه داده‌ها:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9471 entries, 0 to 9470\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Date           9357 non-null   object \n",
            " 1   Time           9357 non-null   object \n",
            " 2   CO(GT)         9357 non-null   object \n",
            " 3   PT08.S1(CO)    9357 non-null   float64\n",
            " 4   NMHC(GT)       9357 non-null   float64\n",
            " 5   C6H6(GT)       9357 non-null   object \n",
            " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
            " 7   NOx(GT)        9357 non-null   float64\n",
            " 8   PT08.S3(NOx)   9357 non-null   float64\n",
            " 9   NO2(GT)        9357 non-null   float64\n",
            " 10  PT08.S4(NO2)   9357 non-null   float64\n",
            " 11  PT08.S5(O3)    9357 non-null   float64\n",
            " 12  T              9357 non-null   object \n",
            " 13  RH             9357 non-null   object \n",
            " 14  AH             9357 non-null   object \n",
            " 15  Unnamed: 15    0 non-null      float64\n",
            " 16  Unnamed: 16    0 non-null      float64\n",
            "dtypes: float64(10), object(7)\n",
            "memory usage: 1.2+ MB\n",
            "None\n",
            "\n",
            "تعداد مقدارهای NaN در هر ستون:\n",
            "PT08.S1(CO)       114\n",
            "NMHC(GT)          114\n",
            "PT08.S2(NMHC)     114\n",
            "NOx(GT)           114\n",
            "PT08.S3(NOx)      114\n",
            "NO2(GT)           114\n",
            "PT08.S4(NO2)      114\n",
            "PT08.S5(O3)       114\n",
            "Unnamed: 15      9471\n",
            "Unnamed: 16      9471\n",
            "dtype: int64\n",
            "\n",
            "ابعاد داده‌ها بعد از حذف مقدارهای NaN: (9357, 8)\n",
            "\n",
            "تعداد مقدار NaN در X: 0\n",
            "تعداد مقدار Inf در X: 0\n",
            "ابعاد X بعد از پردازش: (9357, 7)\n",
            "ابعاد y بعد از پردازش: (9357, 1)\n",
            "\n",
            "✅ داده‌ها با موفقیت نرمال‌سازی شدند!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# --- بارگذاری و پیش‌پردازش داده‌ها ---\n",
        "df = pd.read_csv(\"/content/AirQualityUCI.csv\", sep=';', encoding='utf-8', low_memory=False)\n",
        "\n",
        "# انتخاب ستون‌های عددی و حذف مقدارهای خالی\n",
        "df_numeric = df.select_dtypes(include=[np.number]).dropna(axis=1, how='all').dropna()\n",
        "\n",
        "# جداسازی ویژگی‌ها و خروجی\n",
        "X = df_numeric.iloc[:, :-1].values\n",
        "y = df_numeric.iloc[:, -1].values.reshape(-1, 1)\n",
        "\n",
        "# جایگذاری مقدارهای NaN و Inf با مقدار میانگین\n",
        "X = np.nan_to_num(X, nan=np.nanmean(X))\n",
        "y = np.nan_to_num(y, nan=np.nanmean(y))\n",
        "\n",
        "# نرمال‌سازی داده‌ها\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y).flatten()\n",
        "\n",
        "# تقسیم داده‌ها به train (60%)، validation (20%) و test (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.4, random_state=42, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "# --- پیاده‌سازی مدل RBF (SVR) ---\n",
        "rbf_model = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
        "rbf_model.fit(X_train, y_train)\n",
        "y_pred_rbf = rbf_model.predict(X_test)\n",
        "\n",
        "# --- پیاده‌سازی مدل ANFIS با PyTorch ---\n",
        "class ANFIS(nn.Module):\n",
        "    def __init__(self, n_inputs, n_rules):\n",
        "        super(ANFIS, self).__init__()\n",
        "        self.n_rules = n_rules\n",
        "        self.n_inputs = n_inputs\n",
        "\n",
        "        # لایه‌های فازی (Gaussian Membership Functions)\n",
        "        self.mu = nn.Parameter(torch.randn(n_rules, n_inputs))\n",
        "        self.sigma = nn.Parameter(torch.randn(n_rules, n_inputs))\n",
        "\n",
        "        # ضرایب قوانین فازی\n",
        "        self.rule_weights = nn.Parameter(torch.randn(n_rules, n_inputs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # محاسبه عضویت گوسی\n",
        "        membership = torch.exp(-((x.unsqueeze(1) - self.mu) ** 2) / (2 * self.sigma ** 2))\n",
        "        rule_activation = torch.prod(membership, dim=2)\n",
        "\n",
        "        # محاسبه خروجی\n",
        "        weighted_rules = rule_activation @ self.rule_weights\n",
        "        output = weighted_rules.sum(dim=1, keepdim=True) / (rule_activation.sum(dim=1, keepdim=True) + 1e-6)\n",
        "        return output\n",
        "\n",
        "# تعریف مدل ANFIS\n",
        "d = X_train.shape[1]  # تعداد ویژگی‌ها\n",
        "anfis_model = ANFIS(n_inputs=d, n_rules=5)\n",
        "optimizer = optim.Adam(anfis_model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# تبدیل داده‌ها به تنسورهای PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# آموزش مدل ANFIS\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = anfis_model(X_train_tensor)\n",
        "    loss = criterion(y_pred, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# پیش‌بینی با مدل ANFIS\n",
        "y_pred_anfis = anfis_model(X_test_tensor).detach().numpy().flatten()\n",
        "\n",
        "# --- مقایسه عملکرد مدل‌ها ---\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"{model_name} -> RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "evaluate_model(y_test, y_pred_rbf, \"RBF Model\")\n",
        "evaluate_model(y_test, y_pred_anfis, \"ANFIS Model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pra2skfaApMf",
        "outputId": "a08d8a1b-0eff-4f4d-e968-b3010bf8057a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.9293\n",
            "Epoch 10, Loss: 0.6350\n",
            "Epoch 20, Loss: 0.5192\n",
            "Epoch 30, Loss: 0.4827\n",
            "Epoch 40, Loss: 0.4634\n",
            "RBF Model -> RMSE: 0.2683, R²: 0.9289\n",
            "ANFIS Model -> RMSE: 0.6523, R²: 0.5798\n"
          ]
        }
      ]
    }
  ]
}